import logging
from typing import Any
import numpy as np
import pandas as pd
from scipy import stats

logger = logging.getLogger(__name__)


class DriftDetector:
    """
    Detect distribution drift using statistical tests.
    
    Supports:
    - PSI (Population Stability Index) for numeric features
    - KS test (Kolmogorov-Smirnov) for continuous distributions
    - Chi-Square test for categorical features
    """
    
    def __init__(self, baseline: dict[str, Any]):
        """
        Initialize drift detector with baseline statistics.
        
        Args:
            baseline: Baseline statistics from training data
                     (generated by BaselineGenerator)
        """
        self.baseline = baseline
        self.baseline_samples = self._generate_baseline_samples()
        logger.info("Initialized DriftDetector with baseline and cached samples")
    
    def _generate_baseline_samples(self, seed: int = 42) -> dict[str, np.ndarray]:
        """
        Pre-generate baseline samples for KS test with reproducibility.
        
        Cached to avoid regenerating random samples on each drift check.
        
        Args:
            seed: Random seed for reproducibility
        
        Returns:
            Dictionary mapping feature names to synthetic baseline samples
        """
        np.random.seed(seed)
        samples = {}
        feature_stats = self.baseline.get("feature_statistics", {})
        
        for feature_name, stats in feature_stats.items():
            if stats.get("type") == "numeric":
                mean = stats.get("mean", 0)
                std = stats.get("std", 1)
                min_val = stats.get("min", -np.inf)
                max_val = stats.get("max", np.inf)
                
                # Generate 10k samples for stable KS test
                raw_samples = np.random.normal(mean, std, size=10000)
                # Clip to valid range to respect bounds
                samples[feature_name] = np.clip(raw_samples, min_val, max_val)
        
        logger.info(f"Generated baseline samples for {len(samples)} numeric features")
        return samples
    
    def detect_feature_drift(self, current_data: pd.DataFrame) -> dict[str, dict[str, float | None]]:
        """
        Detect drift in features.
        
        Args:
            current_data: DataFrame with current production features
        
        Returns:
            Dictionary mapping feature names to drift metrics:
            {
                "age": {"psi": 0.15, "ks_statistic": 0.08, "ks_pvalue": 0.02},
                "income": {"psi": 0.22, "ks_statistic": 0.12, "ks_pvalue": 0.001},
                ...
            }
        """
        feature_stats = self.baseline.get("feature_statistics", {})
        drift_results: dict[str, dict[str, float | None]] = {}
        
        for feature_name, baseline_stats in feature_stats.items():
            if feature_name not in current_data.columns:
                logger.warning(f"Feature '{feature_name}' not in current data, skipping")
                continue
            
            current_values: pd.Series = current_data[feature_name].dropna()
            
            if len(current_values) == 0:
                logger.warning(f"No non-null values for '{feature_name}', skipping")
                continue
            
            feature_type = baseline_stats.get("type")
            
            if feature_type == "numeric":
                drift_results[feature_name] = self._detect_numeric_drift(feature_name, current_values, baseline_stats)
            elif feature_type == "categorical":
                drift_results[feature_name] = self._detect_categorical_drift(feature_name, current_values, baseline_stats)
            else:
                logger.warning(f"Unknown feature type '{feature_type}' for '{feature_name}'")
        
        return drift_results
    
    def detect_prediction_drift(self, current_predictions: np.ndarray) -> dict[str, float | None]:
        """
        Detect drift in model predictions.
        
        Args:
            current_predictions: Array of current prediction probabilities
        
        Returns:
            Dictionary with prediction drift metrics (values can be None if calculation fails):
            {"ks_statistic": 0.15, "ks_pvalue": 0.001, "mean_shift": 0.05}
        """
        pred_stats: dict[str, Any] = self.baseline.get("prediction_statistics", {})
        
        if not pred_stats:
            logger.warning("No prediction statistics in baseline")
            return {}
        
        pred_type: str | None = pred_stats.get("type")
        
        if pred_type == "binary_classification": return self._detect_binary_prediction_drift(current_predictions, pred_stats)
        elif pred_type == "multiclass_classification": return self._detect_multiclass_prediction_drift(current_predictions, pred_stats)
        else:
            logger.warning(f"Unknown prediction type '{pred_type}'")
            return {}
    
    def _detect_numeric_drift(self, feature_name: str, current_values: pd.Series, baseline_stats: dict[str, Any]) -> dict[str, float | None]:
        """
        Detect drift in numeric feature using PSI and KS test.
        
        Args:
            feature_name: Name of the feature
            current_values: Current feature values
            baseline_stats: Baseline statistics for this feature
        
        Returns:
            Dictionary with PSI and KS test results (values can be None if calculation fails)
        """
        results: dict[str, float | None] = {}

        try:
            baseline_percentiles: dict[str, float] = baseline_stats.get("percentiles", {})
            if baseline_percentiles:
                bins = [
                    baseline_stats.get("min", 0),
                    baseline_percentiles.get("p25", 0),
                    baseline_percentiles.get("p50", 0),
                    baseline_percentiles.get("p75", 0),
                    baseline_stats.get("max", 1),
                ]
                
                expected_dist = np.array([0.25, 0.25, 0.25, 0.25])
                
                current_hist, _ = np.histogram(current_values, bins=bins)
                actual_dist = current_hist / current_hist.sum()
                
                psi = self._calculate_psi(actual_dist, expected_dist)
                results["psi"] = psi
        
        except Exception as e:
            logger.error(f"Error calculating PSI for '{feature_name}': {e}")
            results["psi"] = None
        
        # KS test (compare distributions using cached baseline sample)
        try:
            # Use pre-generated baseline sample for consistent results
            if feature_name in self.baseline_samples:
                baseline_sample = self.baseline_samples[feature_name]
                ks_stat, ks_pvalue = stats.ks_2samp(current_values, baseline_sample)
                results["ks_statistic"] = float(ks_stat)
                results["ks_pvalue"] = float(ks_pvalue)
            else:
                logger.warning(f"No cached baseline sample for '{feature_name}'")
                results["ks_statistic"] = None
                results["ks_pvalue"] = None
        
        except Exception as e:
            logger.error(f"Error calculating KS test for '{feature_name}': {e}")
            results["ks_statistic"] = None
            results["ks_pvalue"] = None

        # Mean shift
        try:
            mean_shift = abs(current_values.mean() - baseline_stats.get("mean", 0))
            results["mean_shift"] = float(mean_shift)
        except Exception as e:
            logger.error(f"Error calculating mean shift for '{feature_name}': {e}")
            results["mean_shift"] = None
        return results
    
    def _detect_categorical_drift(self, feature_name: str, current_values: pd.Series, baseline_stats: dict[str, Any]) -> dict[str, float | None]:
        """
        Detect drift in categorical feature using Chi-Square test.
        
        Args:
            feature_name: Name of the feature
            current_values: Current feature values
            baseline_stats: Baseline statistics for this feature
        
        Returns:
            Dictionary with Chi-Square test results (values can be None if calculation fails)
        """
        results: dict[str, float | None] = {}
        
        try:
            baseline_dist = baseline_stats.get("top_categories", {})
            
            if not baseline_dist:
                logger.warning(f"No baseline distribution for '{feature_name}'")
                return results
            current_dist = current_values.value_counts(normalize=True).to_dict()
            all_categories = set(baseline_dist.keys()) | set(current_dist.keys())
            
            baseline_probs = np.array([baseline_dist.get(cat, 0.0) for cat in all_categories])
            current_probs = np.array([current_dist.get(cat, 0.0) for cat in all_categories])

            expected_counts = baseline_probs * len(current_values)
            observed_counts = current_probs * len(current_values)
            
            mask = expected_counts > 0
            expected_counts = expected_counts[mask]
            observed_counts = observed_counts[mask]
            
            if len(expected_counts) > 1:
                chi2_stat, chi2_pvalue = stats.chisquare(observed_counts, expected_counts)
                results["chi2_statistic"] = float(chi2_stat)
                results["chi2_pvalue"] = float(chi2_pvalue)
            
        except Exception as e:
            logger.error(f"Error calculating Chi-Square for '{feature_name}': {e}")
            results["chi2_statistic"] = None
            results["chi2_pvalue"] = None
        
        return results
    
    def _detect_binary_prediction_drift(self, current_predictions: np.ndarray, pred_stats: dict[str, Any]) -> dict[str, float | None]:
        """
        Detect drift in binary classification predictions.
        Args:
            current_predictions: Current prediction probabilities
            pred_stats: Baseline prediction statistics
        Returns:
            Dictionary with drift metrics (values can be None if calculation fails)
        """
        results: dict[str, float | None] = {}
        
        try:
            baseline_mean = pred_stats.get("mean_probability", 0.5)
            current_mean = float(current_predictions.mean())
            
            results["mean_shift"] = abs(current_mean - baseline_mean)

            baseline_hist = pred_stats.get("histogram", {})
            if baseline_hist:
                bin_edges = np.array(baseline_hist.get("bin_edges", []))
                baseline_counts = np.array(baseline_hist.get("counts", []))
                
                if len(bin_edges) > 1 and len(baseline_counts) > 0:
                    current_counts, _ = np.histogram(current_predictions, bins=bin_edges)

                    baseline_dist = baseline_counts / baseline_counts.sum()
                    current_dist = current_counts / current_counts.sum() if current_counts.sum() > 0 else current_counts

                    psi = self._calculate_psi(current_dist, baseline_dist)
                    results["psi"] = psi
            
        except Exception as e:
            logger.error(f"Error detecting prediction drift: {e}")
        return results
    
    def _detect_multiclass_prediction_drift(self, current_predictions: np.ndarray, pred_stats: dict[str, Any]) -> dict[str, float | None]:
        """
        Detect drift in multiclass predictions.
        
        Args:
            current_predictions: Current prediction probabilities (2D array)
            pred_stats: Baseline prediction statistics
        
        Returns:
            Dictionary with drift metrics (values can be None if calculation fails)
        """
        results: dict[str, float | None] = {}
        
        try:
            class_dists = pred_stats.get("class_distributions", [])
            
            for i, class_dist in enumerate(class_dists):
                if i < current_predictions.shape[1]:
                    baseline_mean = class_dist.get("mean", 0.0)
                    current_mean = float(current_predictions[:, i].mean())
                    
                    results[f"class_{i}_mean_shift"] = abs(current_mean - baseline_mean)
        
        except Exception as e:
            logger.error(f"Error detecting multiclass drift: {e}")
        
        return results
    
    @staticmethod
    def _calculate_psi(actual: np.ndarray, expected: np.ndarray, epsilon: float = 1e-10) -> float:
        """
        Calculate Population Stability Index (PSI).
        
        PSI = Î£ (actual% - expected%) * ln(actual% / expected%)
        
        Args:
            actual: Actual distribution counts (will be normalized)
            expected: Expected distribution counts (will be normalized)
            epsilon: Small value to avoid log(0)
        
        Returns:
            PSI value (0 = no drift, >0.2 = significant drift)
        """
        # Normalize to probabilities (must sum to 1)
        actual = actual / actual.sum()
        expected = expected / expected.sum()
        
        # Add epsilon to avoid log(0)
        actual = np.maximum(actual, epsilon)
        expected = np.maximum(expected, epsilon)
        
        psi = np.sum((actual - expected) * np.log(actual / expected))
        
        return float(psi)
